{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['https_proxy'] = \"http://hpc-proxy00.city.ac.uk:3128\"\n",
    "# os.environ['http_proxy'] = “http://hpc-proxy00.city.ac.uk:3128”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),     \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='.'\n",
    "filedir=os.path.join(os.getcwd(),filepath,'Vegetable Images')\n",
    "batch_size=128\n",
    "\n",
    "for i in os.listdir(filedir):\n",
    "    if(i=='train'):\n",
    "        train_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_train\n",
    "    )\n",
    "    elif(i=='test'):\n",
    "        test_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_test\n",
    "    )\n",
    "    elif(i=='validation'):\n",
    "        valid_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_test\n",
    "    )\n",
    "    else:\n",
    "        raise(Exception('Unexpected error occurred.'))\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
    "valid_loader=DataLoader(valid_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1=16\n",
    "D2=32\n",
    "D3=64\n",
    "D4=128\n",
    "D5=256\n",
    "\n",
    "A1=512\n",
    "A2=256\n",
    "num_classes=15\n",
    "input_pix=224\n",
    "num_neurons=int(np.floor(np.floor(np.floor(input_pix/2)/2)/2)**2*D5)\n",
    "input=3\n",
    "class my_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(input, D1, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(D1,D2, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(D2, D3, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(D3 ,D4, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(D4, D5, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(D5 ,D5, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            \n",
    "            nn.Linear(num_neurons,A1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(A1, A2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(A2,num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "opt=torch.optim.Adam\n",
    "lr=1e-3\n",
    "model=my_nn().to(device)\n",
    "\n",
    "def train(model,train_loader,epochs,lr,opt,loss_func):\n",
    "    model.train()\n",
    "    losslog=[]\n",
    "    optimizer=opt(model.parameters(),lr)\n",
    "    for _,(x,y) in enumerate(train_loader):\n",
    "        batch_x=x.to(device)\n",
    "        ypred=model(batch_x)\n",
    "        loss=loss_func(ypred,y.to(device))\n",
    "        losslog.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return losslog\n",
    "\n",
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    batch_loss=[]\n",
    "    tally=0\n",
    "    total=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,(x,y) in enumerate(test_loader):\n",
    "            ypred=model(x.to(device))\n",
    "            tally+=torch.tensor(torch.sum(ypred.argmax(1)==y.to(device)))\n",
    "            total+=len(ypred)\n",
    "            batch_loss.append(torch.tensor(torch.sum(ypred.argmax(1)==y.to(device)))/len(ypred))\n",
    "    \n",
    "    return tally/total\n",
    "            \n",
    "\n",
    "def fit(model,train_loader,test_loader,val_loader,epochs,lr=1e-3,opt=torch.optim.SGD,loss_func=F.cross_entropy):\n",
    "    train_acc_log=[]\n",
    "    test_acc_log=[]\n",
    "    valid_acc_log=[]\n",
    "    for iter in range(epochs):\n",
    "        #training step\n",
    "        train_log=train(model,train_loader,epochs,lr,opt,loss_func)\n",
    "            \n",
    "        train_acc=evaluate(model,train_loader)\n",
    "        test_acc=evaluate(model,test_loader)\n",
    "        valid_acc=evaluate(model,test_loader)\n",
    "        print(\"Epoch [{}], train acc: {:.2f}, test acc: {:.2f}, val acc: {:.2f}\".format(epochs, train_acc, test_acc, valid_acc))\n",
    "        #evaluate step\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        valid_acc_log.append(valid_acc)\n",
    "    \n",
    "    print('Training Complete')\n",
    "    return train_acc,test_acc,valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc,test_acc,valid_acc=fit(model,train_loader,test_loader,valid_loader,20,opt=torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
