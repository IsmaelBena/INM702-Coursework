{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['https_proxy'] = \"http://hpc-proxy00.city.ac.uk:3128\"\n",
    "# # os.environ['http_proxy'] = “http://hpc-proxy00.city.ac.uk:3128”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),     \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 10000\n",
      "    Root location: c:\\Users\\Sean\\Documents\\GitHub\\INM702-Coursework\\.\\Landscape Classification\\Training Data\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "filepath='.'\n",
    "filedir=os.path.join(os.getcwd(),filepath,'Landscape Classification')\n",
    "batch_size=16\n",
    "\n",
    "# dataset=datasets.ImageFolder(\n",
    "#     root=filedir,\n",
    "#     transform=transform_train,\n",
    "# )\n",
    "\n",
    "# train_dataset,test_dataset,valid_dataset=torch.utils.data.random_split(dataset, [0.8,0.1,0.1],\n",
    "# generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "for i in os.listdir(filedir):\n",
    "    if(i=='Training Data'):\n",
    "        train_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_train\n",
    "    )\n",
    "    elif(i=='Testing Data'):\n",
    "        test_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_test\n",
    "    )\n",
    "    elif(i=='Validation Data'):\n",
    "        valid_dataset=datasets.ImageFolder(\n",
    "            root=os.path.join(filedir,i),\n",
    "            transform=transform_test\n",
    "    )\n",
    "print(train_dataset)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
    "valid_loader=DataLoader(valid_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1=32\n",
    "D2=64\n",
    "D3=128\n",
    "\n",
    "A1=512\n",
    "A2=256\n",
    "num_classes=5\n",
    "input_pix=224\n",
    "num_neurons=int(np.floor(np.floor(np.floor(input_pix/2)/2)/2)**2*D3)\n",
    "input=3\n",
    "class my_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(input, D1, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(D1, D2, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(D2, D3, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            \n",
    "            nn.Linear(num_neurons,A1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(A1, A2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(A2,num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading checkpoint in case of outside problems interrupting training\n",
    "mydir='MODELS'\n",
    "save_path=os.path.join(mydir, 'mymodel.pt')\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-3\n",
    "epochs = 15\n",
    "opt=torch.optim.Adam\n",
    "model=my_nn().to(device)\n",
    "\n",
    "# if not os.path.isdir(mydir):\n",
    "#     os.makedirs(mydir)\n",
    "\n",
    "# if os.path.isfile(save_path):\n",
    "#     checkpoint=torch.load(save_path)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     model.to(device)\n",
    "#     opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#     start=checkpoint['epoch']\n",
    "#     best_valid=checkpoint['valid_acc']\n",
    "#     best_test=checkpoint['test_acc']\n",
    "#     print('Starting from epoch', start)\n",
    "# else:\n",
    "#     print('No Checkpoint, starting from scratch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,epochs,lr,opt,loss_func):\n",
    "    model.train()\n",
    "    losslog=[]\n",
    "    optimizer=opt\n",
    "    for _,(x,y) in enumerate(train_loader):\n",
    "        batch_x=x.to(device)\n",
    "        ypred=model(batch_x)\n",
    "        loss=loss_func(ypred,y.to(device))\n",
    "        losslog.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return losslog\n",
    "\n",
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in enumerate(test_loader):\n",
    "            batch_x = model(x.to(device))\n",
    "            acc += (batch_x.argmax(1) == y.to(device)).sum().item()\n",
    "            \n",
    "    #return the accuracy from the epoch     \n",
    "    return acc / len(test_loader.dataset)\n",
    "            \n",
    "\n",
    "def fit(model,train_loader,test_loader,val_loader,epochs,optimizer,lr=1e-3,loss_func=F.cross_entropy):\n",
    "    train_acc_log=[]\n",
    "    test_acc_log=[]\n",
    "    valid_acc_log=[]\n",
    "    best_valid=0\n",
    "    best_test=0\n",
    "    opt=optimizer(model.parameters(),lr)\n",
    "    for iter in range(epochs):\n",
    "        #training step\n",
    "        train_log=train(model,train_loader,epochs,lr,opt,loss_func)\n",
    "            \n",
    "        train_acc=evaluate(model,train_loader)\n",
    "        test_acc=evaluate(model,test_loader)\n",
    "        valid_acc=evaluate(model,test_loader)\n",
    "        print(\"Epoch [{}], train acc: {:.2f}, test acc: {:.2f}, val acc: {:.2f}\".format(iter, train_acc, test_acc, valid_acc))\n",
    "        #evaluate step\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        valid_acc_log.append(valid_acc)\n",
    "        \n",
    "        # #saving models to avoid running through entire epochs\n",
    "        # if(valid_acc>best_valid and test_acc>=best_test):\n",
    "        #     best_valid=valid_acc\n",
    "        #     best_test=test_acc\n",
    "            \n",
    "        #     torch.save(\n",
    "        #         {\n",
    "        #             'epochs': epochs,\n",
    "        #             'model_state_dict': model.state_dict(),\n",
    "        #             'opt_state_dict': opt.state_dict(),\n",
    "        #             'train_acc': train_acc,\n",
    "        #             'test_acc': test_acc,\n",
    "        #             'valid_acc': valid_acc,\n",
    "        #         }, save_path\n",
    "        #     )\n",
    "        #     print('Model Saved for epoch {}'.format(iter))\n",
    "    \n",
    "    \n",
    "    print('Training Complete')\n",
    "    return train_acc,test_acc,valid_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train acc: 0.71, test acc: 0.71, val acc: 0.71\n",
      "Epoch [1], train acc: 0.74, test acc: 0.72, val acc: 0.72\n",
      "Epoch [2], train acc: 0.74, test acc: 0.72, val acc: 0.72\n",
      "Epoch [3], train acc: 0.87, test acc: 0.79, val acc: 0.79\n",
      "Epoch [4], train acc: 0.93, test acc: 0.76, val acc: 0.76\n",
      "Epoch [5], train acc: 0.97, test acc: 0.79, val acc: 0.79\n",
      "Epoch [6], train acc: 0.98, test acc: 0.80, val acc: 0.80\n",
      "Epoch [7], train acc: 0.99, test acc: 0.78, val acc: 0.78\n",
      "Epoch [8], train acc: 0.98, test acc: 0.78, val acc: 0.78\n",
      "Epoch [9], train acc: 0.99, test acc: 0.76, val acc: 0.76\n",
      "Epoch [10], train acc: 0.99, test acc: 0.79, val acc: 0.79\n",
      "Epoch [11], train acc: 0.99, test acc: 0.79, val acc: 0.79\n",
      "Epoch [12], train acc: 0.98, test acc: 0.78, val acc: 0.78\n",
      "Epoch [13], train acc: 0.99, test acc: 0.79, val acc: 0.79\n",
      "Epoch [14], train acc: 0.99, test acc: 0.79, val acc: 0.79\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "train_acc,test_acc,valid_acc=fit(model,train_loader,test_loader,valid_loader,epochs,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Trainable                 Param #\n",
       "============================================================================================================================================\n",
       "AlexNet                                  [16, 3, 224, 224]         [16, 5]                   Partial                   --\n",
       "├─Sequential: 1-1                        [16, 3, 224, 224]         [16, 256, 6, 6]           False                     --\n",
       "│    └─Conv2d: 2-1                       [16, 3, 224, 224]         [16, 64, 55, 55]          False                     (23,296)\n",
       "│    └─ReLU: 2-2                         [16, 64, 55, 55]          [16, 64, 55, 55]          --                        --\n",
       "│    └─MaxPool2d: 2-3                    [16, 64, 55, 55]          [16, 64, 27, 27]          --                        --\n",
       "│    └─Conv2d: 2-4                       [16, 64, 27, 27]          [16, 192, 27, 27]         False                     (307,392)\n",
       "│    └─ReLU: 2-5                         [16, 192, 27, 27]         [16, 192, 27, 27]         --                        --\n",
       "│    └─MaxPool2d: 2-6                    [16, 192, 27, 27]         [16, 192, 13, 13]         --                        --\n",
       "│    └─Conv2d: 2-7                       [16, 192, 13, 13]         [16, 384, 13, 13]         False                     (663,936)\n",
       "│    └─ReLU: 2-8                         [16, 384, 13, 13]         [16, 384, 13, 13]         --                        --\n",
       "│    └─Conv2d: 2-9                       [16, 384, 13, 13]         [16, 256, 13, 13]         False                     (884,992)\n",
       "│    └─ReLU: 2-10                        [16, 256, 13, 13]         [16, 256, 13, 13]         --                        --\n",
       "│    └─Conv2d: 2-11                      [16, 256, 13, 13]         [16, 256, 13, 13]         False                     (590,080)\n",
       "│    └─ReLU: 2-12                        [16, 256, 13, 13]         [16, 256, 13, 13]         --                        --\n",
       "│    └─MaxPool2d: 2-13                   [16, 256, 13, 13]         [16, 256, 6, 6]           --                        --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [16, 256, 6, 6]           [16, 256, 6, 6]           --                        --\n",
       "├─Sequential: 1-3                        [16, 9216]                [16, 5]                   True                      --\n",
       "│    └─Dropout: 2-14                     [16, 9216]                [16, 9216]                --                        --\n",
       "│    └─Linear: 2-15                      [16, 9216]                [16, 4096]                True                      37,752,832\n",
       "│    └─ReLU: 2-16                        [16, 4096]                [16, 4096]                --                        --\n",
       "│    └─Dropout: 2-17                     [16, 4096]                [16, 4096]                --                        --\n",
       "│    └─Linear: 2-18                      [16, 4096]                [16, 4096]                True                      16,781,312\n",
       "│    └─ReLU: 2-19                        [16, 4096]                [16, 4096]                --                        --\n",
       "│    └─Linear: 2-20                      [16, 4096]                [16, 1000]                True                      4,097,000\n",
       "│    └─ReLU: 2-21                        [16, 1000]                [16, 1000]                --                        --\n",
       "│    └─Dropout: 2-22                     [16, 1000]                [16, 1000]                --                        --\n",
       "│    └─Linear: 2-23                      [16, 1000]                [16, 5]                   True                      5,005\n",
       "============================================================================================================================================\n",
       "Total params: 61,105,845\n",
       "Trainable params: 58,636,149\n",
       "Non-trainable params: 2,469,696\n",
       "Total mult-adds (Units.GIGABYTES): 11.44\n",
       "============================================================================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 63.26\n",
       "Params size (MB): 244.42\n",
       "Estimated Total Size (MB): 317.31\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_alexnet = models.alexnet(weights='DEFAULT').to(device)\n",
    "for layers in transfer_alexnet.parameters():\n",
    "    layers.requires_grad=False #Freeze layers\n",
    "\n",
    "dropout=0.2\n",
    "num_classes=5\n",
    "transfer_alexnet.classifier= nn.Sequential( #Rebuilding the classifier to be the same as Alex Net but an added Dense layer for the number of classes for this dataset (5)\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(1000,num_classes)\n",
    "        ).to(device)\n",
    "\n",
    "# summary(transfer_alexnet, input_size=(batch_size,3,224,224),col_names=[\"input_size\",\"output_size\",\"trainable\",\"num_params\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train acc: 0.96, test acc: 0.85, val acc: 0.85\n",
      "Epoch [1], train acc: 0.93, test acc: 0.86, val acc: 0.86\n",
      "Epoch [2], train acc: 0.96, test acc: 0.87, val acc: 0.87\n",
      "Epoch [3], train acc: 0.96, test acc: 0.85, val acc: 0.85\n",
      "Epoch [4], train acc: 0.97, test acc: 0.86, val acc: 0.86\n",
      "Epoch [5], train acc: 0.97, test acc: 0.85, val acc: 0.85\n",
      "Epoch [6], train acc: 0.98, test acc: 0.85, val acc: 0.85\n",
      "Epoch [7], train acc: 0.98, test acc: 0.82, val acc: 0.82\n",
      "Epoch [8], train acc: 0.98, test acc: 0.86, val acc: 0.86\n",
      "Epoch [9], train acc: 0.99, test acc: 0.84, val acc: 0.84\n",
      "Epoch [10], train acc: 0.99, test acc: 0.86, val acc: 0.86\n",
      "Epoch [11], train acc: 0.99, test acc: 0.85, val acc: 0.85\n",
      "Epoch [12], train acc: 0.98, test acc: 0.88, val acc: 0.88\n",
      "Epoch [13], train acc: 0.99, test acc: 0.85, val acc: 0.85\n",
      "Epoch [14], train acc: 0.98, test acc: 0.87, val acc: 0.87\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "train_acc,test_acc,valid_acc=fit(transfer_alexnet,train_loader,test_loader,valid_loader,epochs,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
